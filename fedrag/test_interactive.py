#!/usr/bin/env python3
"""
Test script for the interactive mode functionality.
This simulates what happens when a user asks a question.
"""

import sys
import os

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from fedrag.retriever import Retriever
from fedrag.llm_querier import LLMQuerier
from fedrag.corpus_splitter import CorpusSplitter


def simulate_interactive_query(question: str):
    """Simulate an interactive query without the federated infrastructure."""
    
    print("ğŸ” Simulating FedRAG Interactive Query")
    print("=" * 50)
    print(f"Question: {question}")
    
    # Initialize components
    retriever = Retriever()
    splitter = CorpusSplitter()
    parts = splitter.list_available_parts()
    
    if not parts:
        print("âŒ No corpus parts found. Please run split_corpus.py first.")
        return
    
    print(f"ğŸ“š Querying {len(parts)} corpus parts...")
    
    # Simulate querying each client (corpus part)
    all_docs = []
    all_scores = []
    
    for i, part in enumerate(parts, 1):
        print(f"  Client {i} ({part})...")
        try:
            results = retriever.query_faiss_index(part, question, knn=2)
            for doc_id, doc_data in results.items():
                all_docs.append(doc_data['content'])
                all_scores.append(doc_data['score'])
        except Exception as e:
            print(f"    Error: {e}")
    
    print(f"ğŸ“Š Retrieved {len(all_docs)} documents total")
    
    # Sort by score (lower is better for L2 distance)
    sorted_indices = sorted(range(len(all_scores)), key=lambda i: all_scores[i])
    sorted_docs = [all_docs[i] for i in sorted_indices[:5]]  # Top 5
    
    print("ğŸ¤– Generating answer...")
    
    # Simulate LLM response (without actually loading the model for testing)
    print("\n" + "=" * 50)
    print("ğŸ“– SIMULATED FEDRAG ANSWER")
    print("=" * 50)
    
    print("ğŸ“š Top sources:")
    for i, doc in enumerate(sorted_docs[:3], 1):
        preview = doc[:80].replace('\n', ' ') + "..."
        print(f"  {i}. {preview}")
    
    print(f"\nğŸ¯ Question: {question}")
    print("ğŸ¤– Answer: [This would be generated by the LLM based on the retrieved documents]")
    print("   The federated system found relevant information across multiple medical textbooks.")
    
    return sorted_docs


def main():
    print("FedRAG Interactive Mode Test")
    print("=" * 30)
    
    # Test with some sample medical questions
    test_questions = [
        "What are the symptoms of hypertension?",
        "How is diabetes diagnosed?",
        "What are the side effects of aspirin?",
        "What causes heart attacks?",
        "How is pneumonia treated?"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*60}")
        print(f"TEST {i}/{len(test_questions)}")
        print('='*60)
        
        docs = simulate_interactive_query(question)
        
        if docs:
            print(f"âœ… Successfully retrieved {len(docs)} documents")
        else:
            print("âŒ Failed to retrieve documents")
        
        if i < len(test_questions):
            input("\nPress Enter to continue to next test...")
    
    print(f"\n{'='*60}")
    print("ğŸ‰ Interactive Mode Test Complete!")
    print("='*60")
    print("\nTo run the actual interactive mode:")
    print("1. Make sure you have 5 corpus parts (run split_corpus.py if needed)")
    print("2. Run: flwr run")
    print("3. The system will prompt you for questions interactively")


if __name__ == "__main__":
    main() 